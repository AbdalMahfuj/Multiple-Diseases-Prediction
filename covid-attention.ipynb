{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This classification model was trained and validated on 3,328 images and 807 images, respectively. As there was imbalance of database provided, sampling was based on the least number of class's images.","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"# libraries for files preparation\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport shutil\n\n# libraries for CNN models and plotting\nimport tensorflow as tf\nimport tensorflow.keras.layers as tfl\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.layers import MaxPool2D , Flatten,GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\nfrom keras.models import Model\nimport matplotlib.pyplot as plt\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:29:57.708042Z","iopub.execute_input":"2022-06-18T18:29:57.708290Z","iopub.status.idle":"2022-06-18T18:30:03.959938Z","shell.execute_reply.started":"2022-06-18T18:29:57.708262Z","shell.execute_reply":"2022-06-18T18:30:03.959185Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Sampling","metadata":{}},{"cell_type":"code","source":"# install openpyxl to read excel files\n!pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:10.437999Z","iopub.execute_input":"2022-06-18T18:30:10.438258Z","iopub.status.idle":"2022-06-18T18:30:20.155838Z","shell.execute_reply.started":"2022-06-18T18:30:10.438230Z","shell.execute_reply":"2022-06-18T18:30:20.154911Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"covid = pd.read_excel('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID.metadata.xlsx')\ncovid.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:36.452350Z","iopub.execute_input":"2022-06-18T18:30:36.452664Z","iopub.status.idle":"2022-06-18T18:30:37.186139Z","shell.execute_reply.started":"2022-06-18T18:30:36.452623Z","shell.execute_reply":"2022-06-18T18:30:37.185394Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"normal = pd.read_excel('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal.metadata.xlsx')\nnormal.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:39.970998Z","iopub.execute_input":"2022-06-18T18:30:39.971258Z","iopub.status.idle":"2022-06-18T18:30:40.908840Z","shell.execute_reply.started":"2022-06-18T18:30:39.971231Z","shell.execute_reply":"2022-06-18T18:30:40.908126Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"viral_pneumonia = pd.read_excel('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia.metadata.xlsx')\nviral_pneumonia.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:44.880969Z","iopub.execute_input":"2022-06-18T18:30:44.881835Z","iopub.status.idle":"2022-06-18T18:30:45.032269Z","shell.execute_reply.started":"2022-06-18T18:30:44.881792Z","shell.execute_reply":"2022-06-18T18:30:45.031457Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Check the numbers of each cases\nprint(\"Covid cases: \", str(len(covid)))\nprint(\"Normal cases: \", str(len(normal)))\nprint(\"Viral Pneumonia cases: \", str(len(viral_pneumonia)))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:48.068304Z","iopub.execute_input":"2022-06-18T18:30:48.068578Z","iopub.status.idle":"2022-06-18T18:30:48.076047Z","shell.execute_reply.started":"2022-06-18T18:30:48.068530Z","shell.execute_reply":"2022-06-18T18:30:48.075206Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The least number of each class is 1345. Therefore, set the sample size to 1345 samples.","metadata":{}},{"cell_type":"code","source":"SAMPLE_SIZE = 1345","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:50.386337Z","iopub.execute_input":"2022-06-18T18:30:50.386922Z","iopub.status.idle":"2022-06-18T18:30:50.394010Z","shell.execute_reply.started":"2022-06-18T18:30:50.386875Z","shell.execute_reply":"2022-06-18T18:30:50.393301Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# add label for each case\ncovid['label'] = 0\nnormal['label'] = 1\nviral_pneumonia['label'] = 2","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:53.625110Z","iopub.execute_input":"2022-06-18T18:30:53.625688Z","iopub.status.idle":"2022-06-18T18:30:53.635192Z","shell.execute_reply.started":"2022-06-18T18:30:53.625649Z","shell.execute_reply":"2022-06-18T18:30:53.634397Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# drop non-related columns\ncovid = covid[['FILE NAME', 'label']]\nnormal = normal[['FILE NAME', 'label']]\nviral_pneumonia = viral_pneumonia[['FILE NAME', 'label']]","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:30:57.775022Z","iopub.execute_input":"2022-06-18T18:30:57.775313Z","iopub.status.idle":"2022-06-18T18:30:57.787819Z","shell.execute_reply.started":"2022-06-18T18:30:57.775284Z","shell.execute_reply":"2022-06-18T18:30:57.787090Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# take a look to covid dataframe\ncovid.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:01.696896Z","iopub.execute_input":"2022-06-18T18:31:01.697488Z","iopub.status.idle":"2022-06-18T18:31:01.705935Z","shell.execute_reply.started":"2022-06-18T18:31:01.697453Z","shell.execute_reply":"2022-06-18T18:31:01.705072Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# sampling data for covid and normal cases\ndf_0 = covid.sample(SAMPLE_SIZE, random_state=26)\ndf_1 = normal.sample(SAMPLE_SIZE, random_state=26)\n\n# concat dataframes\ndata = pd.concat([df_0, df_1, viral_pneumonia], axis=0).reset_index(drop=True)\n\n# check numbers of each label\ndata['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:10.795038Z","iopub.execute_input":"2022-06-18T18:31:10.795294Z","iopub.status.idle":"2022-06-18T18:31:10.815396Z","shell.execute_reply.started":"2022-06-18T18:31:10.795267Z","shell.execute_reply":"2022-06-18T18:31:10.814773Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# shuffle data\ndata = shuffle(data)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:13.268904Z","iopub.execute_input":"2022-06-18T18:31:13.269462Z","iopub.status.idle":"2022-06-18T18:31:13.283031Z","shell.execute_reply.started":"2022-06-18T18:31:13.269425Z","shell.execute_reply":"2022-06-18T18:31:13.282277Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Train Test Split","metadata":{}},{"cell_type":"code","source":"df_train, df_val = train_test_split(data, test_size=0.20, random_state=26, stratify=data['label'])\n\nprint(df_train.shape)\nprint(df_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:19.403693Z","iopub.execute_input":"2022-06-18T18:31:19.403956Z","iopub.status.idle":"2022-06-18T18:31:19.417212Z","shell.execute_reply.started":"2022-06-18T18:31:19.403929Z","shell.execute_reply":"2022-06-18T18:31:19.416247Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df_val['FILE NAME']","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:23.691085Z","iopub.execute_input":"2022-06-18T18:31:23.691583Z","iopub.status.idle":"2022-06-18T18:31:23.702174Z","shell.execute_reply.started":"2022-06-18T18:31:23.691525Z","shell.execute_reply":"2022-06-18T18:31:23.701457Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df_train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:26.495587Z","iopub.execute_input":"2022-06-18T18:31:26.496258Z","iopub.status.idle":"2022-06-18T18:31:26.506200Z","shell.execute_reply.started":"2022-06-18T18:31:26.496222Z","shell.execute_reply":"2022-06-18T18:31:26.505450Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df_val['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:28.682348Z","iopub.execute_input":"2022-06-18T18:31:28.682616Z","iopub.status.idle":"2022-06-18T18:31:28.688953Z","shell.execute_reply.started":"2022-06-18T18:31:28.682588Z","shell.execute_reply":"2022-06-18T18:31:28.688301Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Creating Directories","metadata":{}},{"cell_type":"code","source":"# Create a new directory\nbase_dir = 'base_dir'\nos.mkdir(base_dir)\n\n\n# create 2 folders inside 'base_dir':\n# base_dir\n  ## train_dir\n     ### covid\n     ### normal\n     ### viral_pneumonia\n  ## val_dir\n     ### covid\n     ### normal\n     ### viral_pneumonia\n\n# create a path to 'base_dir' to which we will join the names of the new folders\n# train_dir\ntrain_dir = os.path.join(base_dir, 'train_dir')\nos.mkdir(train_dir)\n\n# val_dir\nval_dir = os.path.join(base_dir, 'val_dir')\nos.mkdir(val_dir)\n\n# [CREATE FOLDERS INSIDE THE TRAIN AND VALIDATION FOLDERS]\n# Inside each folder we create seperate folders for each class\n\n# create new folders inside train_dir\ntrain_covid = os.path.join(train_dir, 'covid')\nos.mkdir(train_covid)\ntrain_normal = os.path.join(train_dir, 'normal')\nos.mkdir(train_normal)\ntrain_viral_pneumonia = os.path.join(train_dir, 'viral pneumonia')\nos.mkdir(train_viral_pneumonia)\n\n# create new folders inside val_dir\nval_covid = os.path.join(val_dir, 'covid')\nos.mkdir(val_covid)\nval_normal = os.path.join(val_dir, 'normal')\nos.mkdir(val_normal)\nval_viral_pneumonia = os.path.join(val_dir, 'viral pneumonia')\nos.mkdir(val_viral_pneumonia)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:32.017680Z","iopub.execute_input":"2022-06-18T18:31:32.018197Z","iopub.status.idle":"2022-06-18T18:31:32.029134Z","shell.execute_reply.started":"2022-06-18T18:31:32.018164Z","shell.execute_reply":"2022-06-18T18:31:32.028468Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# check the folders in train_dir\nos.listdir('base_dir/train_dir')","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:35.932677Z","iopub.execute_input":"2022-06-18T18:31:35.933219Z","iopub.status.idle":"2022-06-18T18:31:35.938798Z","shell.execute_reply.started":"2022-06-18T18:31:35.933182Z","shell.execute_reply":"2022-06-18T18:31:35.938106Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Transfer Images into Folders","metadata":{}},{"cell_type":"code","source":"train_list = list(df_train['FILE NAME'])\nval_list = list(df_val['FILE NAME'])\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:38.889857Z","iopub.execute_input":"2022-06-18T18:31:38.890148Z","iopub.status.idle":"2022-06-18T18:31:38.895571Z","shell.execute_reply.started":"2022-06-18T18:31:38.890115Z","shell.execute_reply":"2022-06-18T18:31:38.894799Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Copy images to train_dir folder\nfor image in train_list:\n    \n    # add .png extension \n    filename = image + '.png'\n    # get the label for a certain image\n    target = int(data.loc[data['FILE NAME'] == image, ['label']].values)\n    \n    # match the target with the folder's name and source path of the image\n    if target == 0:\n        label = 'covid'\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images', filename)\n        \n    if target == 1:\n        label = 'normal'\n        # As 'FILE NAME's in .xlsx file begins with 'NORMAL' but real file names begin with 'Normal'\n        filename = filename.capitalize()\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images', filename)\n        \n    if target == 2:\n        label = 'viral pneumonia'\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/images', filename)\n  \n    # destination path to image\n    dst = os.path.join(train_dir, label, filename)\n    \n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)\n\n# Copy images to val_dir folder\nfor image in val_list:\n    \n    # add .png extension \n    filename = image + '.png'\n    # get the label for a certain image\n    target = int(data.loc[data['FILE NAME'] == image, ['label']].values)\n    \n    # match the target with the folder's name and source path of the image\n    if target == 0:\n        label = 'covid'\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/images', filename)\n        \n    if target == 1:\n        label = 'normal'\n        filename = filename.capitalize()\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/images', filename)\n        \n    if target == 2:\n        label = 'viral pneumonia'\n        src = os.path.join('../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Viral Pneumonia/images', filename)\n  \n    # destination path to image\n    dst = os.path.join(val_dir, label, filename)\n    \n    # copy the image from the source to the destination\n    shutil.copyfile(src, dst)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:31:43.286419Z","iopub.execute_input":"2022-06-18T18:31:43.286953Z","iopub.status.idle":"2022-06-18T18:32:16.354627Z","shell.execute_reply.started":"2022-06-18T18:31:43.286918Z","shell.execute_reply":"2022-06-18T18:32:16.353929Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# check the number of train images in each folder\nprint(len(os.listdir('base_dir/train_dir/covid')))\nprint(len(os.listdir('base_dir/train_dir/normal')))\nprint(len(os.listdir('base_dir/train_dir/viral pneumonia')))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:32:53.066857Z","iopub.execute_input":"2022-06-18T18:32:53.067109Z","iopub.status.idle":"2022-06-18T18:32:53.076315Z","shell.execute_reply.started":"2022-06-18T18:32:53.067083Z","shell.execute_reply":"2022-06-18T18:32:53.075610Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# check the number of validation images in each folder\nprint(len(os.listdir('base_dir/val_dir/covid')))\nprint(len(os.listdir('base_dir/val_dir/normal')))\nprint(len(os.listdir('base_dir/val_dir/viral pneumonia')))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:33:00.189880Z","iopub.execute_input":"2022-06-18T18:33:00.190134Z","iopub.status.idle":"2022-06-18T18:33:00.196877Z","shell.execute_reply.started":"2022-06-18T18:33:00.190106Z","shell.execute_reply":"2022-06-18T18:33:00.195991Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"==================== End of Files Preparation ====================","metadata":{}},{"cell_type":"markdown","source":"# Image Classification","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 32\nIMG_SIZE = (256  , 256)\ntrain_directory = \"base_dir/train_dir\"\nval_directory = \"base_dir/val_dir\"\n                                  ","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:33:09.369095Z","iopub.execute_input":"2022-06-18T18:33:09.369377Z","iopub.status.idle":"2022-06-18T18:33:09.374194Z","shell.execute_reply.started":"2022-06-18T18:33:09.369332Z","shell.execute_reply":"2022-06-18T18:33:09.373256Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## Generate Train/Val Dataset","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,\n        rotation_range=0.2,\n        shear_range=0.2,\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_directory(\n        train_directory,\n        target_size=IMG_SIZE,\n        color_mode='rgb',\n        batch_size=32,\n        class_mode='categorical')\nvalidation_generator = test_datagen.flow_from_directory(\n        val_directory,\n        target_size=IMG_SIZE,\n        color_mode='rgb',\n        batch_size=32,\n        shuffle=False,\n        class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:33:23.325888Z","iopub.execute_input":"2022-06-18T18:33:23.326150Z","iopub.status.idle":"2022-06-18T18:33:23.646509Z","shell.execute_reply.started":"2022-06-18T18:33:23.326113Z","shell.execute_reply":"2022-06-18T18:33:23.645750Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# check classes in train_generator\ntrain_generator.class_indices","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:33:37.756600Z","iopub.execute_input":"2022-06-18T18:33:37.757059Z","iopub.status.idle":"2022-06-18T18:33:37.762956Z","shell.execute_reply.started":"2022-06-18T18:33:37.757025Z","shell.execute_reply":"2022-06-18T18:33:37.762095Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Take a look to some of samples in `train_generator`","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(9):\n    plt.subplot(3,3, i+1)\n    img, label = train_generator.next()\n    plt.imshow(img[0], cmap='gray')\n    dic = {0:'Covid', 1:'Normal', 2:'Viral Pneumonia'}\n    plt.title(dic.get(np.where(label[0]==1)[0][0]))\n    plt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:33:47.178856Z","iopub.execute_input":"2022-06-18T18:33:47.179587Z","iopub.status.idle":"2022-06-18T18:33:51.851937Z","shell.execute_reply.started":"2022-06-18T18:33:47.179521Z","shell.execute_reply":"2022-06-18T18:33:51.848917Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Model Fitting\nThe model architecture is based on VGG-16 model, including 3x3 filter for convolutions layer and 2x2 filter for pooling layers, doubling the number of filters and three fully-connected layers.","metadata":{}},{"cell_type":"code","source":"def covid_model1(IMG_SIZE):\n    input_shape = IMG_SIZE + (1, )\n    model = Sequential([\n        Conv2D(32, (3, 3), activation=\"relu\", padding='same',input_shape=input_shape),\n        MaxPooling2D(pool_size = (2, 2)), \n        Conv2D(32, (3, 3), padding='same', activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)), \n        Conv2D(64, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Conv2D(64, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Conv2D(128, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Conv2D(128, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Conv2D(128, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Conv2D(256, (3, 3), padding='same',activation=\"relu\"),\n        MaxPooling2D(pool_size = (2, 2)),\n        Flatten(),\n       \n        Dense(units=128, activation='relu'),\n        Dense(units=64, activation='relu'),\n        Dense(units=3, activation='softmax')\n    ])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-14T11:25:38.108273Z","iopub.execute_input":"2022-04-14T11:25:38.108555Z","iopub.status.idle":"2022-04-14T11:25:38.119105Z","shell.execute_reply.started":"2022-04-14T11:25:38.108525Z","shell.execute_reply":"2022-04-14T11:25:38.118331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention","metadata":{}},{"cell_type":"code","source":"class ChannelAttention(tf.keras.layers.Layer):\n      def __init__(self, filters, ratio):\n        super(ChannelAttention, self).__init__()\n        self.filters = filters\n        self.ratio = ratio\n      \n        def build(self, input_shape):\n            self.shared_layer_one = tf.keras.layers.Dense(self.filters//self.ratio,\n                             activation='relu', kernel_initializer='he_normal', \n                              use_bias=True, \n                              bias_initializer='zeros')\n            self.shared_layer_two = tf.keras.layers.Dense(self.filters,\n                             kernel_initializer='he_normal',\n                             use_bias=True,\n                             bias_initializer='zeros')\n\n        def call(self, inputs):\n            # AvgPool\n            avg_pool = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n            \n\n            avg_pool = self.shared_layer_one(avg_pool)\n            avg_pool = self.shared_layer_two(avg_pool)\n\n            # MaxPool\n            max_pool = tf.keras.layers.GlobalMaxPooling2D()(inputs)\n            max_pool = tf.keras.layers.Reshape((1,1,filters))(max_pool)\n\n            max_pool = shared_layer_one(max_pool)\n            max_pool = shared_layer_two(max_pool)\n\n\n            attention = tf.keras.layers.Add()([avg_pool,max_pool])\n            attention = tf.keras.layers.Activation('sigmoid')(attention)\n            \n            return tf.keras.layers.Multiply()([inputs, attention])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:35:10.361468Z","iopub.execute_input":"2022-06-18T18:35:10.362209Z","iopub.status.idle":"2022-06-18T18:35:10.371689Z","shell.execute_reply.started":"2022-06-18T18:35:10.362169Z","shell.execute_reply":"2022-06-18T18:35:10.370789Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(tf.keras.layers.Layer):\n      def __init__(self, kernel_size):\n        super(SpatialAttention, self).__init__()\n        self.kernel_size = kernel_size\n        def build(self, input_shape):\n            self.conv2d = tf.keras.layers.Conv2D(filters = 1,\n                    kernel_size=self.kernel_size,\n                    strides=1,\n                    padding='same',\n                    activation='sigmoid',\n                    kernel_initializer='he_normal',\n                    use_bias=False)\n\n        def call(self, inputs):\n            \n            # AvgPool\n            avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(inputs)\n            \n            # MaxPool\n            max_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.max(x, axis=3, keepdims=True))(inputs)\n\n            attention = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n\n            attention = self.conv2d(attention)\n\n\n            return tf.keras.layers.multiply([inputs, attention]) ","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:35:14.398173Z","iopub.execute_input":"2022-06-18T18:35:14.398827Z","iopub.status.idle":"2022-06-18T18:35:14.406903Z","shell.execute_reply.started":"2022-06-18T18:35:14.398790Z","shell.execute_reply":"2022-06-18T18:35:14.406195Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"size=256","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:39:10.960626Z","iopub.execute_input":"2022-06-18T18:39:10.961349Z","iopub.status.idle":"2022-06-18T18:39:10.965170Z","shell.execute_reply.started":"2022-06-18T18:39:10.961311Z","shell.execute_reply":"2022-06-18T18:39:10.964348Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, 3, input_shape=(size,size,3), activation='relu', padding='same'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    ChannelAttention(32, 8),\n    SpatialAttention(7),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    ChannelAttention(64, 8),\n    SpatialAttention(7),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n    ChannelAttention(128, 8),\n    SpatialAttention(7),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n    ChannelAttention(256, 8),\n    SpatialAttention(7),\n    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'),\n    ChannelAttention(512, 8),\n    SpatialAttention(7),\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(3, activation='softmax' )\n])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:39:12.903165Z","iopub.execute_input":"2022-06-18T18:39:12.904020Z","iopub.status.idle":"2022-06-18T18:39:13.105414Z","shell.execute_reply.started":"2022-06-18T18:39:12.903967Z","shell.execute_reply":"2022-06-18T18:39:13.104701Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:39:17.127165Z","iopub.execute_input":"2022-06-18T18:39:17.127427Z","iopub.status.idle":"2022-06-18T18:39:17.147696Z","shell.execute_reply.started":"2022-06-18T18:39:17.127398Z","shell.execute_reply":"2022-06-18T18:39:17.146994Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.compile(optimizer= tf.keras.optimizers.Adam(0.0001),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, \n                                                  restore_best_weights=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:49:12.288369Z","iopub.execute_input":"2022-06-18T18:49:12.288627Z","iopub.status.idle":"2022-06-18T18:49:12.301964Z","shell.execute_reply.started":"2022-06-18T18:49:12.288600Z","shell.execute_reply":"2022-06-18T18:49:12.301189Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"\nhistoryattention = simple_cnn_with_attention.fit(train_generator, epochs=50,\n                                                 validation_data = validation_generator, \n                                                 callbacks=[early_stopping])","metadata":{"execution":{"iopub.status.busy":"2022-06-18T18:59:19.963370Z","iopub.execute_input":"2022-06-18T18:59:19.963817Z","iopub.status.idle":"2022-06-18T19:10:51.224958Z","shell.execute_reply.started":"2022-06-18T18:59:19.963778Z","shell.execute_reply":"2022-06-18T19:10:51.224217Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"print(f\"Test accuracy: {simple_cnn_with_attention.evaluate(validation_generator)[1]}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:03.729786Z","iopub.execute_input":"2022-06-18T19:11:03.730055Z","iopub.status.idle":"2022-06-18T19:11:06.651575Z","shell.execute_reply.started":"2022-06-18T19:11:03.730014Z","shell.execute_reply":"2022-06-18T19:11:06.650863Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(f\"Train accuracy: {simple_cnn_with_attention.evaluate(train_generator)[1]}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-10T09:55:19.593132Z","iopub.execute_input":"2022-05-10T09:55:19.594068Z","iopub.status.idle":"2022-05-10T09:56:42.025138Z","shell.execute_reply.started":"2022-05-10T09:55:19.594024Z","shell.execute_reply":"2022-05-10T09:56:42.024341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plotLearningCurve(historyattention,13)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:39.965860Z","iopub.execute_input":"2022-06-18T19:11:39.966143Z","iopub.status.idle":"2022-06-18T19:11:40.612916Z","shell.execute_reply.started":"2022-06-18T19:11:39.966113Z","shell.execute_reply":"2022-06-18T19:11:40.612275Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.save('attention4.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T14:06:15.546107Z","iopub.execute_input":"2022-05-02T14:06:15.546404Z","iopub.status.idle":"2022-05-02T14:06:15.584876Z","shell.execute_reply.started":"2022-05-02T14:06:15.54637Z","shell.execute_reply":"2022-05-02T14:06:15.58343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Display\nfrom IPython.display import Image, display\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:52.299281Z","iopub.execute_input":"2022-06-18T19:11:52.299583Z","iopub.status.idle":"2022-06-18T19:11:52.303788Z","shell.execute_reply.started":"2022-06-18T19:11:52.299533Z","shell.execute_reply":"2022-06-18T19:11:52.302925Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"img_size = (256, 256)","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:55.264706Z","iopub.execute_input":"2022-06-18T19:11:55.265242Z","iopub.status.idle":"2022-06-18T19:11:55.269286Z","shell.execute_reply.started":"2022-06-18T19:11:55.265209Z","shell.execute_reply":"2022-06-18T19:11:55.268149Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:57.879500Z","iopub.execute_input":"2022-06-18T19:11:57.879950Z","iopub.status.idle":"2022-06-18T19:11:57.888262Z","shell.execute_reply.started":"2022-06-18T19:11:57.879895Z","shell.execute_reply":"2022-06-18T19:11:57.887214Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"\nimg_path=\"./base_dir/val_dir/normal/Normal-1255.png\"\nimg_array3 =  get_img_array('./base_dir/val_dir/viral pneumonia/Viral Pneumonia-885.png', size=img_size)\n# Prepare image\nimg_array = get_img_array(img_path, size=img_size)\n\n# Print what the two top predicted classes are\npreds = simple_cnn_with_attention.predict(img_array3)\nprediction = np.argmax(preds)\nprint(\"Predicted:\", prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgarray2 =  get_img_array('./base_dir/val_dir/covid/COVID-100.png', size=img_size)\nimg_array3 =  get_img_array('./base_dir/val_dir/viral pneumonia/Viral Pneumonia-999.png', size=img_size)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:03:12.070846Z","iopub.execute_input":"2022-05-10T14:03:12.071122Z","iopub.status.idle":"2022-05-10T14:03:12.082441Z","shell.execute_reply.started":"2022-05-10T14:03:12.071089Z","shell.execute_reply":"2022-05-10T14:03:12.081754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = simple_cnn_with_attention.predict(imgarray2) \ni = np.argmax(preds[0])\n\n# `conv2d_19` - remember this, we talked about it earlier \nicam = GradCAM(simple_cnn_with_attention, i, 'channel_attention_9') \nheatmap = icam.compute_heatmap(imgarray2)\nheatmap = cv2.resize(heatmap, (200, 200))\n\nimage = cv2.imread('./base_dir/val_dir/covid/COVID-100.png')\nimage = cv2.resize(image, (200, 200))\nprint(heatmap.shape, image.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:36:39.328844Z","iopub.execute_input":"2022-05-10T14:36:39.329141Z","iopub.status.idle":"2022-05-10T14:36:39.408923Z","shell.execute_reply.started":"2022-05-10T14:36:39.329109Z","shell.execute_reply":"2022-05-10T14:36:39.408238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(heatmap, output) = icam.overlay_heatmap(heatmap, image, alpha=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:36:42.706333Z","iopub.execute_input":"2022-05-10T14:36:42.706935Z","iopub.status.idle":"2022-05-10T14:36:42.712014Z","shell.execute_reply.started":"2022-05-10T14:36:42.706896Z","shell.execute_reply":"2022-05-10T14:36:42.711145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 3,figsize=(50,15))\n\nax[0].imshow(heatmap)\nax[1].imshow(image)\nax[2].imshow(output)\nplt.savefig('vgg16_gradcam_covid.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T14:36:46.047653Z","iopub.execute_input":"2022-05-10T14:36:46.048078Z","iopub.status.idle":"2022-05-10T14:36:47.000716Z","shell.execute_reply.started":"2022-05-10T14:36:46.048045Z","shell.execute_reply":"2022-05-10T14:36:47.000078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nimport tensorflow as tf\nimport numpy as np\nimport cv2\n\nclass GradCAM:\n    def __init__(self, model, classIdx, layerName=None):\n        # store the model, the class index used to measure the class\n        # activation map, and the layer to be used when visualizing\n        # the class activation map\n        self.model = model\n        self.classIdx = classIdx\n        self.layerName = layerName\n        # if the layer name is None, attempt to automatically find\n        # the target output layer\n        if self.layerName is None:\n            self.layerName = self.find_target_layer()\n\n    def find_target_layer(self):\n        # attempt to find the final convolutional layer in the network\n        # by looping over the layers of the network in reverse order\n        for layer in reversed(self.model.layers):\n            # check to see if the layer has a 4D output\n            if len(layer.output_shape) == 4:\n                return layer.name\n        # otherwise, we could not find a 4D layer so the GradCAM\n        # algorithm cannot be applied\n        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n\n\n    def compute_heatmap(self, image, eps=1e-8):\n        # construct our gradient model by supplying (1) the inputs\n        # to our pre-trained model, (2) the output of the (presumably)\n        # final 4D layer in the network, and (3) the output of the\n        # softmax activations from the model\n        gradModel = Model(\n            inputs=[self.model.inputs],\n            outputs=[self.model.get_layer(self.layerName).output, self.model.output])\n\n        # record operations for automatic differentiation\n        with tf.GradientTape() as tape:\n            # cast the image tensor to a float-32 data type, pass the\n            # image through the gradient model, and grab the loss\n            # associated with the specific class index\n            inputs = tf.cast(image, tf.float32)\n            (convOutputs, predictions) = gradModel(inputs)\n            \n            loss = predictions[:, tf.argmax(predictions[0])]\n    \n        # use automatic differentiation to compute the gradients\n        grads = tape.gradient(loss, convOutputs)\n\n        # compute the guided gradients\n        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n        castGrads = tf.cast(grads > 0, \"float32\")\n        guidedGrads = castConvOutputs * castGrads * grads\n        # the convolution and guided gradients have a batch dimension\n        # (which we don't need) so let's grab the volume itself and\n        # discard the batch\n        convOutputs = convOutputs[0]\n        guidedGrads = guidedGrads[0]\n\n        # compute the average of the gradient values, and using them\n        # as weights, compute the ponderation of the filters with\n        # respect to the weights\n        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n\n        # grab the spatial dimensions of the input image and resize\n        # the output class activation map to match the input image\n        # dimensions\n        (w, h) = (image.shape[2], image.shape[1])\n        heatmap = cv2.resize(cam.numpy(), (w, h))\n        # normalize the heatmap such that all values lie in the range\n        # [0, 1], scale the resulting values to the range [0, 255],\n        # and then convert to an unsigned 8-bit integer\n        numer = heatmap - np.min(heatmap)\n        denom = (heatmap.max() - heatmap.min()) + eps\n        heatmap = numer / denom\n        heatmap = (heatmap * 255).astype(\"uint8\")\n        # return the resulting heatmap to the calling function\n        return heatmap\n\n    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n                        colormap=cv2.COLORMAP_VIRIDIS):\n        # apply the supplied color map to the heatmap and then\n        # overlay the heatmap on the input image\n        heatmap = cv2.applyColorMap(heatmap, colormap)\n        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n        # return a 2-tuple of the color mapped heatmap and the output,\n        # overlaid image\n        return (heatmap, output)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:54:16.17698Z","iopub.execute_input":"2022-05-10T12:54:16.177426Z","iopub.status.idle":"2022-05-10T12:54:16.192772Z","shell.execute_reply.started":"2022-05-10T12:54:16.177361Z","shell.execute_reply":"2022-05-10T12:54:16.191669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img","metadata":{"execution":{"iopub.status.busy":"2022-04-23T17:58:46.439016Z","iopub.execute_input":"2022-04-23T17:58:46.439732Z","iopub.status.idle":"2022-04-23T17:58:46.444669Z","shell.execute_reply.started":"2022-04-23T17:58:46.439678Z","shell.execute_reply":"2022-04-23T17:58:46.443703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classlabel = ['COVID','Normal','Viral Pneumonia']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tf_explain.core.grad_cam import GradCAM\nfrom utils.visualize import plotImages, plotHistory, explainGradCam","metadata":{"execution":{"iopub.status.busy":"2022-04-14T14:09:28.431334Z","iopub.execute_input":"2022-04-14T14:09:28.431888Z","iopub.status.idle":"2022-04-14T14:09:28.454473Z","shell.execute_reply.started":"2022-04-14T14:09:28.431829Z","shell.execute_reply":"2022-04-14T14:09:28.453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotLearningCurve(history,epochs):\n  epochRange = range(1,epochs+1)\n  fig, ax = plt.subplots(1,2,figsize=(40,15))\n  ax[0].plot(epochRange,history.history['accuracy'],'b',label = 'Training Accuracy', linewidth=7.0)\n  ax[0].plot(epochRange,history.history['val_accuracy'],'r',label = 'Validation Accuracy',linewidth=7.0)\n  ax[0].set_title('Training and Validation accuracy',fontsize = 45)\n  ax[0].set_xlabel('Epoch', fontsize = 45)\n  ax[0].set_ylabel('Accuracy', fontsize = 45)\n  ax[0].tick_params(axis='both', labelsize=45)\n  ax[0].legend(fontsize=45)\n  ax[0].set_ylim([0, 1])\n  ax[0].grid(color='gray', linestyle='--')\n  ax[1].plot(epochRange,history.history['loss'],'b',label = 'Training Loss',linewidth=7.0)\n  ax[1].plot(epochRange,history.history['val_loss'],'r',label = 'Validation Loss',linewidth=7.0)\n  ax[1].set_title('Training and Validation loss',fontsize = 45)\n  ax[1].set_xlabel('Epoch', fontsize = 45)\n  ax[1].set_ylabel('Loss', fontsize = 45)\n  ax[1].tick_params(axis='both', labelsize=45)\n  ax[1].legend(fontsize=45)\n  ax[1].grid(color='gray', linestyle='--')\n \n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T19:11:33.396614Z","iopub.execute_input":"2022-06-18T19:11:33.396901Z","iopub.status.idle":"2022-06-18T19:11:33.411246Z","shell.execute_reply.started":"2022-06-18T19:11:33.396869Z","shell.execute_reply":"2022-06-18T19:11:33.408512Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# create history loss and accuracy function\ndef plot_loss_acc(history):\n    train_loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    epochs = range(len(train_loss))\n\n    plt.figure(figsize=(8,6))\n    plt.plot(epochs, train_loss, color='b', label='Train')\n    plt.plot(epochs, val_loss, color='r', label='Validation')\n    plt.legend()\n    plt.title('Model Loss')\n    \n    \n    plt.figure(figsize=(8,6))\n    plt.plot(epochs, acc, color='b', label='Train')\n    plt.plot(epochs, val_acc, color='r', label='Validation')\n    plt.legend()\n    plt.title('Model Accuracy')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T14:47:08.292382Z","iopub.execute_input":"2022-04-23T14:47:08.292655Z","iopub.status.idle":"2022-04-23T14:47:08.303181Z","shell.execute_reply.started":"2022-04-23T14:47:08.292627Z","shell.execute_reply":"2022-04-23T14:47:08.302511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(history)","metadata":{"execution":{"iopub.status.busy":"2022-04-14T12:50:34.707267Z","iopub.execute_input":"2022-04-14T12:50:34.707543Z","iopub.status.idle":"2022-04-14T12:50:35.133387Z","shell.execute_reply.started":"2022-04-14T12:50:34.707512Z","shell.execute_reply":"2022-04-14T12:50:35.132707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(r)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T15:10:45.629977Z","iopub.execute_input":"2022-04-23T15:10:45.630241Z","iopub.status.idle":"2022-04-23T15:10:46.047318Z","shell.execute_reply.started":"2022-04-23T15:10:45.630211Z","shell.execute_reply":"2022-04-23T15:10:46.046608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss_acc(historyattention)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T14:47:19.249942Z","iopub.execute_input":"2022-04-23T14:47:19.250375Z","iopub.status.idle":"2022-04-23T14:47:19.651892Z","shell.execute_reply.started":"2022-04-23T14:47:19.250338Z","shell.execute_reply":"2022-04-23T14:47:19.651197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ClassificaitonConfusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:35:09.207445Z","iopub.execute_input":"2022-05-10T10:35:09.207777Z","iopub.status.idle":"2022-05-10T10:35:09.296611Z","shell.execute_reply.started":"2022-05-10T10:35:09.207734Z","shell.execute_reply":"2022-05-10T10:35:09.29498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict classes of validation dataset\nval_predict = simple_cnn_with_attention.predict(validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:29:40.081546Z","iopub.execute_input":"2022-05-10T13:29:40.082077Z","iopub.status.idle":"2022-05-10T13:29:43.506594Z","shell.execute_reply.started":"2022-05-10T13:29:40.082039Z","shell.execute_reply":"2022-05-10T13:29:43.505831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_class = np.argmax(val_predict, axis=1)\npredict_class = predict_class.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:29:46.485195Z","iopub.execute_input":"2022-05-10T13:29:46.48546Z","iopub.status.idle":"2022-05-10T13:29:46.489311Z","shell.execute_reply.started":"2022-05-10T13:29:46.48543Z","shell.execute_reply":"2022-05-10T13:29:46.488653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Covid', 'Normal', 'Viral Pneumonia']\nreport = classification_report(validation_generator.classes, predict_class, target_names=labels)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:29:49.700351Z","iopub.execute_input":"2022-05-10T13:29:49.700928Z","iopub.status.idle":"2022-05-10T13:29:49.713342Z","shell.execute_reply.started":"2022-05-10T13:29:49.700888Z","shell.execute_reply":"2022-05-10T13:29:49.712424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Covid', 'Normal', 'Viral Pneumonia']\nreport = classification_report(validation_generator.classes, predict_class, target_names=labels)\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:35:33.188691Z","iopub.execute_input":"2022-05-10T10:35:33.188942Z","iopub.status.idle":"2022-05-10T10:35:33.200141Z","shell.execute_reply.started":"2022-05-10T10:35:33.188915Z","shell.execute_reply":"2022-05-10T10:35:33.199389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(validation_generator.classes, predict_class)\ncm_df = pd.DataFrame(cm,\n                     index = ['COVID','NORMAL','VIRAL PNEUMONIA'], \n                     columns = ['COVID','NORMAL','VIRAL PNEUMONIA'])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:29:59.200681Z","iopub.execute_input":"2022-05-10T13:29:59.200946Z","iopub.status.idle":"2022-05-10T13:29:59.212344Z","shell.execute_reply.started":"2022-05-10T13:29:59.200916Z","shell.execute_reply":"2022-05-10T13:29:59.21154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True, fmt='d')\nplt.title(\"Confusion Matrixx\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:30:05.680285Z","iopub.execute_input":"2022-05-10T13:30:05.68087Z","iopub.status.idle":"2022-05-10T13:30:05.911266Z","shell.execute_reply.started":"2022-05-10T13:30:05.68083Z","shell.execute_reply":"2022-05-10T13:30:05.910643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing import image","metadata":{"execution":{"iopub.status.busy":"2022-04-29T21:25:40.134802Z","iopub.execute_input":"2022-04-29T21:25:40.135086Z","iopub.status.idle":"2022-04-29T21:25:40.139344Z","shell.execute_reply.started":"2022-04-29T21:25:40.135055Z","shell.execute_reply":"2022-04-29T21:25:40.138578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"./att5.data-00000-of-00001\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T21:26:58.633072Z","iopub.execute_input":"2022-04-29T21:26:58.633391Z","iopub.status.idle":"2022-04-29T21:26:58.663856Z","shell.execute_reply.started":"2022-04-29T21:26:58.633355Z","shell.execute_reply":"2022-04-29T21:26:58.66287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = image.load_img(\"./base_dir/val_dir/covid/COVID-1006.png\", target_size=(256, 256, 1))\ndata = np.expand_dims(data, axis=0)\ndata = data * 1.0 / 255\n\nprint(data.shape)\n\nresult = simple_cnn_with_attention.predict(data)\nprint(result)\nindices = {0: 'COVID', 1: 'normal', 2: 'Viral Pneumonia'}\n        # predicted_class=0\n        # accuracy=95.6\npredicted_class = np.asscalar(np.argmax(result, axis=1))\naccuracy = round(result[0][predicted_class] * 100, 2)\n\nlabel = indices[predicted_class]\nprint(predicted_class)\nprint(accuracy)\nprint(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T22:04:32.842811Z","iopub.execute_input":"2022-04-29T22:04:32.843077Z","iopub.status.idle":"2022-04-29T22:04:33.202689Z","shell.execute_reply.started":"2022-04-29T22:04:32.843048Z","shell.execute_reply":"2022-04-29T22:04:33.201969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GradCam","metadata":{}},{"cell_type":"code","source":"!pip install keras-vis","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:38:46.541606Z","iopub.execute_input":"2022-05-10T10:38:46.541879Z","iopub.status.idle":"2022-05-10T10:38:54.802945Z","shell.execute_reply.started":"2022-05-10T10:38:46.541851Z","shell.execute_reply":"2022-05-10T10:38:54.802045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from vis.utils import utils\nfrom tf_keras_vis.utils.scores import CategoricalScore\nfrom matplotlib import cm\nfrom tf_keras_vis.gradcam import Gradcam\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:39:06.658487Z","iopub.execute_input":"2022-05-10T10:39:06.659274Z","iopub.status.idle":"2022-05-10T10:39:06.665185Z","shell.execute_reply.started":"2022-05-10T10:39:06.659226Z","shell.execute_reply":"2022-05-10T10:39:06.664288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = load_img('./base_dir/val_dir/covid/COVID-1059.png', target_size=(256, 256))\nimg2 = load_img('./base_dir/val_dir/normal/Normal-1009.png', target_size=(256, 256))\nimg3 = load_img('./base_dir/val_dir/viral pneumonia/Viral Pneumonia-106.png', target_size=(256, 256))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:43:25.967229Z","iopub.execute_input":"2022-05-10T10:43:25.96797Z","iopub.status.idle":"2022-05-10T10:43:25.981803Z","shell.execute_reply.started":"2022-05-10T10:43:25.967924Z","shell.execute_reply":"2022-05-10T10:43:25.980905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = np.asarray([np.array(img1), np.array(img2), np.array(img3)])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:43:29.645153Z","iopub.execute_input":"2022-05-10T10:43:29.645441Z","iopub.status.idle":"2022-05-10T10:43:29.651182Z","shell.execute_reply.started":"2022-05-10T10:43:29.645409Z","shell.execute_reply":"2022-05-10T10:43:29.650314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert to numpy array for reshaping\nimg1 = img_to_array(img1)\nimg2 = img_to_array(img2)\nimg3 = img_to_array(img3)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:43:32.332718Z","iopub.execute_input":"2022-05-10T10:43:32.332974Z","iopub.status.idle":"2022-05-10T10:43:32.338905Z","shell.execute_reply.started":"2022-05-10T10:43:32.332945Z","shell.execute_reply":"2022-05-10T10:43:32.337744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reshape to prepare for processing\nimg1 = img1.reshape(1,256,256,3)\nimg2 = img2.reshape(1,256,256,3)\nimg3 = img3.reshape(1,256,256,3)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T10:43:35.410749Z","iopub.execute_input":"2022-05-10T10:43:35.411052Z","iopub.status.idle":"2022-05-10T10:43:35.420774Z","shell.execute_reply.started":"2022-05-10T10:43:35.411016Z","shell.execute_reply":"2022-05-10T10:43:35.419925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yhat1 = simple_cnn_with_attention.predict(img1)\nyhat2 = simple_cnn_with_attention.predict(img2)\nyhat3 = simple_cnn_with_attention.predict(img3)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:39:01.862959Z","iopub.execute_input":"2022-05-10T12:39:01.863314Z","iopub.status.idle":"2022-05-10T12:39:01.981802Z","shell.execute_reply.started":"2022-05-10T12:39:01.863281Z","shell.execute_reply":"2022-05-10T12:39:01.981069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Top 5 classes predicted\nclass_idxs_sorted1 = np.argsort(yhat1.flatten())[::-1]\nclass_idxs_sorted2 = np.argsort(yhat2.flatten())[::-1]\nclass_idxs_sorted3 = np.argsort(yhat3.flatten())[::-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:39:16.110134Z","iopub.execute_input":"2022-05-10T12:39:16.110437Z","iopub.status.idle":"2022-05-10T12:39:16.115767Z","shell.execute_reply.started":"2022-05-10T12:39:16.110402Z","shell.execute_reply":"2022-05-10T12:39:16.114759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classlabel = ['COVID','Normal','Viral Pneumonia']","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:39:24.461113Z","iopub.execute_input":"2022-05-10T12:39:24.461977Z","iopub.status.idle":"2022-05-10T12:39:24.466315Z","shell.execute_reply.started":"2022-05-10T12:39:24.461934Z","shell.execute_reply":"2022-05-10T12:39:24.465281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"topNclass         = 4\n\nprint('\\nfirst image\\n')\nfor i, idx in enumerate(class_idxs_sorted1[:topNclass]):\n    print(\"Top {} predicted class:     Pr(Class={:18} [index={}])={:5.3f}\".format(\n          i + 1,classlabel[idx],idx,yhat3[0,idx]))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T13:28:10.922182Z","iopub.execute_input":"2022-05-10T13:28:10.922447Z","iopub.status.idle":"2022-05-10T13:28:10.928348Z","shell.execute_reply.started":"2022-05-10T13:28:10.922418Z","shell.execute_reply":"2022-05-10T13:28:10.927654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.layers[-1].activation = tf.keras.activations.linear","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:13:59.454002Z","iopub.execute_input":"2022-05-10T11:13:59.454277Z","iopub.status.idle":"2022-05-10T11:13:59.458936Z","shell.execute_reply.started":"2022-05-10T11:13:59.454246Z","shell.execute_reply":"2022-05-10T11:13:59.458223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_classes = ['COVID','Normal','Viral Pneumonia']\nscore = CategoricalScore([0, 1, 2])\n\n# Create Gradcam object\ngradcam = Gradcam(simple_cnn_with_attention,\n                  clone=True)\n\n# Generate heatmap with GradCAM\ncam = gradcam(score,\n              images,\n              penultimate_layer=-3)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:40:52.852956Z","iopub.execute_input":"2022-05-10T12:40:52.853597Z","iopub.status.idle":"2022-05-10T12:40:52.899152Z","shell.execute_reply.started":"2022-05-10T12:40:52.853556Z","shell.execute_reply":"2022-05-10T12:40:52.898259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\nfor i, img_class in enumerate(input_classes):\n    heatmap = np.uint8(cm.jet(cam[i])[..., :4] * 255)\n    ax[i].set_title(img_class, fontsize=16)\n    ax[i].imshow(images[i])\n    ax[i].imshow(heatmap, cmap='jet', alpha=0.5) # overlay\n    ax[i].axis('off')\nplt.tight_layout()\nplt.show()\n# plt.savefig('vgg16_gradcam224.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T12:40:35.170046Z","iopub.execute_input":"2022-05-10T12:40:35.170313Z","iopub.status.idle":"2022-05-10T12:40:35.630999Z","shell.execute_reply.started":"2022-05-10T12:40:35.170282Z","shell.execute_reply":"2022-05-10T12:40:35.630059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tf-explain","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:19:39.647132Z","iopub.execute_input":"2022-05-10T11:19:39.64744Z","iopub.status.idle":"2022-05-10T11:19:47.963614Z","shell.execute_reply.started":"2022-05-10T11:19:39.647409Z","shell.execute_reply":"2022-05-10T11:19:47.962649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install python-utils","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:28:49.845351Z","iopub.execute_input":"2022-05-10T11:28:49.845657Z","iopub.status.idle":"2022-05-10T11:28:57.426825Z","shell.execute_reply.started":"2022-05-10T11:28:49.845627Z","shell.execute_reply":"2022-05-10T11:28:57.42598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from utils.visualize import explainGradCam","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:32:52.848242Z","iopub.execute_input":"2022-05-10T11:32:52.848823Z","iopub.status.idle":"2022-05-10T11:32:52.871685Z","shell.execute_reply.started":"2022-05-10T11:32:52.848783Z","shell.execute_reply":"2022-05-10T11:32:52.870445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_datasets as tfds\nfrom tf_explain.core.grad_cam import GradCAM\nexplainer = GradCAM()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:20:49.591223Z","iopub.execute_input":"2022-05-10T11:20:49.591519Z","iopub.status.idle":"2022-05-10T11:20:50.707485Z","shell.execute_reply.started":"2022-05-10T11:20:49.591479Z","shell.execute_reply":"2022-05-10T11:20:50.706693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label=\"covid\"","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:26:04.39545Z","iopub.execute_input":"2022-05-10T11:26:04.395744Z","iopub.status.idle":"2022-05-10T11:26:04.399794Z","shell.execute_reply.started":"2022-05-10T11:26:04.395715Z","shell.execute_reply":"2022-05-10T11:26:04.398773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainGradCam(explainer, axes[0], img,\n               label,\n               simple_cnn_with_attention,\n               simple_cnn_with_attention.predict(img_array), \n               class_names=['covid', 'normal','viral pneumonia'])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T11:26:06.722286Z","iopub.execute_input":"2022-05-10T11:26:06.722569Z","iopub.status.idle":"2022-05-10T11:26:06.749078Z","shell.execute_reply.started":"2022-05-10T11:26:06.722537Z","shell.execute_reply":"2022-05-10T11:26:06.748207Z"},"trusted":true},"execution_count":null,"outputs":[]}]}